## 빅데이터 분석 기사 

Part 1. 그림으로 단답형 박살내기
  1. 빅데이터 분석 기획
     1.1 빅데이터의 이해 
          - 개인정보 자기결정권 
           - 마이 데이터 
           - 소프트스킬  
           - 암묵지
           - 데이터 분석 전담조직 : 집중구조, 기능 구조, 분산구조 (‘집기분”)
           - 프레이밍 현상 (같은 상황을 다르게 생각하는 것, 예)내로남불?)
           - 핵심 성과 지표 또는 KPI 
      1.2 데이터 분석 계획
            데이터 분석의 우선순위 평가 기준 : 난이도와 시급성 
           - 상향식/하향식 접근방식 
           - 솔루션
           - 시스템 고도화
           - 정보 전략 계획 (ISP)
           - CRM 
           - CSV (,로 구분된 텍스트 데이터 형식)
           - 데이터 분석 방법론  CRISP-DM  
           - 데이터 분석 방법론  KDD (통계적 패턴/규칙이나 지식을 찾기 위해 정리한 방법) 
           - 데이터 분석 방법론 SEMMA (SAS사에서 만든 데이터 마이닝 기능 구성 방법론)
      1.3 데이터 수집 및 저장 계획 
           - 가명처리 
           - 비정형 데이터 수집 도구 
           - 비율척도
           - 스쿱 (Sqoop, 관계형DB와 하둡 사이에서 데이터 이관을 지원하는 도구) 
           - 크롤링 (Crawling, 인터넷 웹사이트로부터 웹문서와 콘텐츠 수집 기술) 
           - 평활화 (Smoothing, 데이터 잡음제거 등 데이터 변환 기술)
           - 하둡 분산 파일 시스템 (HDFS) 
           - API 
           - ETL (데이터 수집, 변환, 저장 데이터웨어하우스 적재 기술) 
           - FTP 
      
  2. 빅데이터 탐색 
       2.1 데이터 전처리 
           - 결측값 / 결측치 (비어있는 값), NaN 
           - 데이터 스케일링 (전처리 과정중에 분석 결과가 왜곡되지 않도록 변수들의 범위를 동일하게 만들어주는 처리 기법)  
           - 박스콕스 (정규분포가 아닌 데이터 셋의 데이터 분산을 안정화하여 정규분포로 변환 기법)
           - 언더 샘플링 (다수의 클래스 데이터를 일부만 선택해 데이터 비율을 맞추는 불균형 데이터 처리 기법) 
           - 오버 샘플링 (소수의 클래스 데이터를 늘려서 데이터 비율을 맞추는 불균형 데이터 처리 기법) 
           - 이상값 / 이상치 (대부분의 데이터가 주로 분포된 범위에서 많이 벗어난 값) 
           - 전진 선택법 (비어있는 상태에서 시작하여 점진적으로 하나씩 추가하는 방법)
           - 차원축소 (비지도 학습 과정 중에 변수들의 정보를 유지하면서 변수의 개수를 줄이는 전처리 방법)
           - 콜드덱 cold-deck (데이터에 누락된 값 결측치를 처리하는 방법) 
           - 콜드덱 대체법 (대체할 자료를 외부출처 또는 이전의 비슷한 연구에서 가져오는 방법) 
           - 파생변수 ( 데이터 전처리 과정에서 단위 변환/변수 결합/표현 형식을 변환해서 기준 변수를 재정의) 
           - 평균 대치법 (평균값으로 결측값을 대치해서 불완전자료를 완전한 자료로 만드는 방법) 
           - 핫덱 대체법 hot-deck (무응답을 현재 진행중인 연구에서 비슷한 성향을 가진 응답자의 자료로 대치)
           - 후진제거법 (변수가 모두 포함된 상태에서 가장 적은 영향을 주는 변수부터 하나씩 제거하는 방법) 
           - ESD (평균에서 표준편차의 3배만큼 떨어진 값을 이상치로 판단하여 데이터의 이상값을 검출하는 방법)            
           - IQR / 사분위수 범위 (데이터 표본을 4개 동일하게 나눈 사분위수 중 3사분위수에서 1사분위수를 뺀 것 (	Q3-Q1)

        2.2 데이터 탐색   
            - 공분산 (2개의 변수 간 상관 정도를 나타내는 지표
            - 왜도 (데이터의 분포를 나타내는 통계량으로 치우진 정도를 의미하는 지표)
            - 탐색적 데이터 분석 또는 EDA(Exploratory data analysis) 

        2.3 통계기법 이해 
            - 귀무가설 (현재까지 주장되어 온 가설로서, 기존과 비교하여 변화나 차이가 없음을 나타내는 가설)
            - 대립가설 (표본을 통해 확실한 근거를 가지고 입증하고자 하는 가설)
            - 분산 (평균으로부터 흩어진 편차의 제곱합) 
            - 분산 분석 
            - 중위값 또는 중앙값 
            - 중앙값 계산 
            - 중심극한정리 (표본수가 무한히 커지면 표본 평균은 정규분포를 따른다는 원칙)
            - 층화 추출법 (표본을 추출하는 방법 중에서 각 계층을 고루 대표할 수 있도록 표본을 임의로 추출)
            - 평균 
            - 표준편차 (분산의 제곱근) 
            - P-Value (귀무가설이 옿다는 가정하에서 얻은 통계량이 귀무가설을 얼마나 지지하는지 나타내는 확률) 

  3. 빅데이터 모델링 
       3.1 분석 모형 설계 
           - 데이터 마이닝 (대규모 데이터 안에서 통계적 규칙이나 패턴을 분석하여 정보를 추출하는 과정)
           - 비지도학습 (레이블이 없는 상태에서 데이터가 어떻게 구성되었는지 알아내는 기계학습 방법) 
           - 지도학습 (레이블이 포함되어 있는 상태에서 데이터를 학습하는 기계학습 방법)
           - 하이퍼 파라미터 (사용자가 직접 설정해주는 값이며, 경험에 의해 결정 가능한 값) 
        3.2 분석 기법 적용 
            - 가지치기 (의사결정나무 형성과정 중에서 오차/부적절한 추론/불필요한 것 가지 제거 방법)
            - 군집간 거리측정 방법 (두 군집간의 유사성을 거리 기반으로 측정하는 기법) 
            - 기울기 소실 (다층 퍼셉트론의 활성화 함수인 스그모이드 함수에서 편미분을 진행할 수록 0에 근접해지는 현상) 
             - 다중공선성 (회귀분석에서 독립변수들 간에 높은 상관관계를 갖는 속성으로, 상관관계가 높은 독립변수를 제거하거나 설명력이 높은 독립변수를 선택하여 문제를 해결해야 하는 속성) 
             - 다차원 척도법 (개체들의 유사성과 비유사성을 측정하여 N차원 공간에 점으로 표현하여 개체들 간의 집단화를 시각적으로 표현하는 분석 방법) 
             - 랜덤 포레스트 (배깅과 부스팅보다 더 많은 무작위성을 주어 약한 학습기를 생성한 후, 이를 선형 결합하여 최종 학습기를 만드는 방법) 
             - 로지스틱 회귀 분석 (방응변수가 범주형인 경우에 적용하는 회귀모형으로, 설명변수/독립변수의 값이 주어질 때 각 범주에 속할 추정확률을 기준치에 따라 분류하는 목적으로 사용하는 분석 기법 
             - 배깅 (여러개의 부트스트랩을 생성하고 각 부트스트랩에서 예측 모형을 만든 후, 최종적으로 결합하여 최적의 예측 모형을 만드는 기법) 
             - 부스팅 (잘못 분류된 개체들에 가중치를 적용하여 새로운 분류 규칙을 만들고, 이 과정을 반복해 최종 모형을 만드는 알고리즘) 
             - 부트스트랩(주어진 자료에서 단순복원 임의추출 방법을 활용하여 동일한 크기의 표본을 여러개 생성하는 샘플링 방법) 
              - 자기 조직화 지도 (차원 축소와 군집화를 동시에 수행하고 고차원의 데이터 셋을 저차원으로 변환하는 비지도 학습 기법) 
              - 서포트 벡터 머신 또는 SVM (공간상애서 최적의 분리 초평면을 찾아서 분류 및 회귀를 수행할 수 있고, 훈련 시간이 상대적으로 느리지만 다른 기계학습 방법 대비 과대적합의 가능성이 낮은 모델) 
             - 손실함수 (신경망 학습에서 평균 제곱 오차 또는 교차 엔트로피 오차를 사용하여 현재의 상태를 나타내는 지표) 
             - 스테밍 ( 텍스트 마이닝의 전처리 과정으로 어형이 변형된 접사를 제거하고, 단어의 원형 또는 어간을 분리하는 과정) 
             - 신뢰도 (연관규칙에서 두 아이템의 연관규칙이 유용한 규칙일 가능성의 척도)
             - 실루엣 (군집 분석에서 군집 내의 응집도와 군집 간의 분리도를 계산하여 1에 가까울수록 군집 결과가 좋은 것이고, -1에 가까울수록 군집결과가 좋지 않은 것으로 해석하는 지표) 
             - 앙상블 기법 (여러 개의 동일한/서로 다른 모형의 예측/분류 결과를 종합하여 최종 의사결정에 활용하는 기법)
             - 역전파 알고리즘 (신경망 학습에서 오차를 출력층에서 입력층으로 전달하여 가중치와 편향을 갱신하는 알고리즘) 
             - 오피니언 마이닝 (주관적인 의견이 포함된 데이터에서 사용자가 게재한 의견과 감정을 나타내는 패턴을 분석하는 기법) 
             - 연관규칙의 지지도, 신뢰도, 향상도 계산  
             - 유전자 알고리즘 
             - 은닉층 (인공신경망에서 입력층과 출력층 사이에 위치하여 내부적으로 동작하는 계층) 
             - 의사결정나무 (트리형태로 모델링하는 분류 예측 모델) 
             - 이동평균모형 (시계열 모델 중에서 자신의 과거값을 사용하여 설명하는 모형) 
             - 정상성 (시계열의 특성이 일정함을 의미하는 속성) 
             - 주성분 분석 (상관성이 높은 변수들을 선형 결합하여 기존의 상관성이 높은 변수들을 요약하고자 축소하는 기법) 
             - 지니지수 계산 (노드의 불순도를 나타내는 값)
             - 지지도 
             - 차분 (현재시점에서 이전의 시점을 뺴는 방법)
             - 텍스트 마이닝 (텍스트 형태로 이루어진 비정형 데이터에서 자연어 처리 방식을 이용해 정보를 추출하는 방법) 
             - 퍼셉트론 (XOR과 같이 선형 분리할 수 없는 문제에 약점을 지닌, 입력층과 출력층으로만 구성된 최초의 인공신경망) 
             - 퍼셉트론의 출력값 계산 
             - 피어슨 상관계수 
             - 향상도 
             - 활성화 함수 
             - 회귀 분석 
             - Apriori 알고리즘 (장바구니 분석 알고리즘) 
             - CNN 또는 합성곱 신경망 
             - K-평균 군집화 (K-means clustering)
             - K-최근접 이웃 알고리즘 (KNN, K-Nearest Neighbor)
             - RNN 또는 순환신경망 (Recurrent Neural network)
   
  4. 빅데이터 결과 해석 
      4.1 분석 모형 평가 및 개선 
           - 과적합 또는 과대적합 
           - 드롭아웃
           - 재현율
           - 최소제곱법 
           - 혼동 행렬 
           - F1 스코어 
           - K-Fold 교차검증 
           - LOOCV 
           - SSE (error sum of square, 예측값과 실제값의 차이인 오차의 제곱합으로 계산)
           - R^2 또는 결정계수 (회귀모형이 실제값을 얼마나 잘 반영하는지를 나타내는 비율, 1에 가까울 수록 잘 반영) 
           - ROC 커브 
           - 특이도를 구하는 계산식 
      4.2 분석 결과 해석 및 활용 
           - 마인드맵 
           - 인포그래픽스 
           - 히트맵
           - TCO
  
Part 2. 파이썬에 발 담그기
  1. 너무 쉬운 파이썬
  2. 파이썬의 잠재력 활용하기 

Part 3. 파이썬으로 데이터 분석 준비하기 
  1. 실습 데이터와 실행 환경 구성하기 
   2. 데이터 분석 절차 체득하기 

Part 4. 파이썬으로 초보 분석가 되기 
  1. 단순한 데이터 분석 
  2. 복잡한 데이터 분석 

Part 5. 파이썬으로 초보 분석가 탈출하기 
   1. 데이터 분석 연습하기 
   2. 분류 모델 수행하기 
   3. 예측 모델 수행하기 
